# DigitalTwin_StudyNotes

### RGBD VS LIDAR
The functional difference between LiDAR and other forms of ToF is that LiDAR uses pulsed lasers to build a point cloud, which is then used to construct a 3D map or image. ToF applications create "depth maps" based on light detection, usually through a standard RGB camera.

### COLMAP and NERF
COLMAP and NERF can be used together in a pipeline for generating photorealistic 3D reconstructions of scenes from a series of 2D images. Here is an example pipeline:

* Capture a series of 2D images of the scene using a camera or cameras.

* Use COLMAP to generate a 3D model of the scene from the set of images, using techniques such as structure-from-motion (SfM) and multi-view stereo (MVS).

* Use the 3D model generated by COLMAP as input to NERF to generate photorealistic images of the scene from novel viewpoints.

* Optionally, refine the 3D model generated by COLMAP using the photorealistic images generated by NERF.

### philosophy question:

What is the point instead of feeding lidar meshes/videos and train it dierectly in the ccmputer vision network, but to represent everything in a virtual world? It makes sense that the collision between objects is important. But if the solo computer vision approach can cover almost every task, what is the point to build a virtual world? Comparing the cost, one hand, it is the cost of building a virtual representation in the simulator and train it in virtual world; on the other hand, it is training from real robots and may hurt the machine and can not generalized well in unseen scenes. Apparently, the former approach is less costly in money, since some algorithms like instant nerf was created. It makes sense.  
